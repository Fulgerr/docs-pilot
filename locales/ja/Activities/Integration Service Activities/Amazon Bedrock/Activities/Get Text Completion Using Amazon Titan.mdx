# Get Text Completion Using Amazon Titan

UiPath.Bedrock.IntegrationService.Activities.TextCompletionUsingAmazon

# Description

Generates a text completion response based on a given prompt using Amazon's
                proprietary LLM called Titan.

# Untitled Section

# Configuration

Model - The model you want to use for the text completion
                        generation.Prompt - The prompt to use for the text completion generation.







* Max token count - The maximum number of tokens allowed for the prompt and generated answer. By default, this field is set to 200.
* Stop sequences - Sequences that cause the model to stop generating completion text.
* Temperature - The amount of randomness injected into the response. This field accepts ranges between 0 and 1. Use a temperature closer to 0 for analytical / multiple choice, and closer to 1 for creative and generative tasks. By default, this field is set to 0.
* Top P - A number between 0 and 1. The lower the number, the fewer tokens are used. By default, this field is set to 1.



* Completion - Top generated text completion. Automatically generated output variable.
* Text completion response object - The full response object for the text completion. Automatically generated output variable.
* Token Count - The total tokens used by the prompt and response. Automatically generated output variable.
