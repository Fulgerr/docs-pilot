# Get Text Completion Using Llama 2

# Description

Generates a text completion response based on a given prompt using Meta Llama 2 models.

# Project compatibility

Windows | Cross-platform

# Configuration

* 
* Model - The model to use for the text completion generation. Select one of the available options from the drop-down list: Llama2 13B, Llama2 70B.
* Prompt - The prompt to use for the text completion generation. This field supports String type input.







* Max token count - The maximum number of tokens allowed for the prompt and generated answer. Fewer tokens are less expensive. Default value is 256. This field supports Int32 type input.
* Temperature - A number between 0 and 2. Higher values make the output more random, while lower values make it more focused and deterministic. By default, this field is set to 0.2. This field supports Double type input.
* Top p - A number between 0 and 1. The lower the number, the fewer tokens are considered. This field supports Int32 type input.



* Completion - Top generated text completion. Automatically generated output variable.
* Text completion response object - The full response object for the text completion. Automatically generated output variable.
