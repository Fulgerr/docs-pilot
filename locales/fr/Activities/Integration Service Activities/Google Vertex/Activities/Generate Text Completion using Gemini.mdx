# Generate Text Completion using Gemini

# Description

Generates a text completion response based on a given prompt using the Gemini
                models.

# Project compatibility

Windows | Cross-platform

# Configuration

* 
* Model name - The large language model (LLM) to utilize for the completion request. Select one of the available options.
* Prompt - The prompt you want to use for the completion(s) generation. This field supports String type input.

* Image - The image file to be used for the completion request. This field supports IResource type input.







* Max output tokens - The maximum number of tokens that can be generated in the response. A token is approximately four characters. 100 tokens correspond to roughly 60-80 words. Specify a lower value for shorter responses and a higher value for potentially longer responses. Default value is 2048.
* Temperature - A number between 0 and 1. Higher values like 0.8 make the output more random, while lower values like 0.2 make it more focused and deterministic. Default value is 0.8.
* Top p - A number between 0 and 1. The lower the number, the lesser the randomness of the result. Defaults to 0.8.
* Top k - A number between 1 and 40. The higher the number, the higher the diversity of generated text. Defaults to 40.



* Text - Automatically generated output variable.
* Text Completion Object - Automatically generated output variable.
